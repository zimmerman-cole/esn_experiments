{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Note to Levi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* I decided that any NRMSE above 1 should probably be considered a 'failure', since its worse than just predicting the mean anyways.\n",
    "______________\n",
    "* I made a method run_test() (under LCESN experiments) which takes a dictionary and filename (to save results) as input and runs tests using the parameters specified in the beginning of the function.\n",
    "    * right now it's written for LCESN, but can be easily changed so that the specific ESN class is passed as a parameter (although we'll have to change the \n",
    "    * For now you have to hard code the params you want in the beginning of the function, but I'll change it soon so you can pass params for grid searching etc.\n",
    "    * The results dictionary keys should contain all the necessary param information. The keys are created in a special way to make show_nrmse_histograms() work correctly.   \n",
    "______________\n",
    "* I also created a function show_nrmse_histograms() which takes one of the results dicts from run_test() and shows some cool histograms of generative NRMSEs yielded using the param settings in the dict. \n",
    "    * There's an example down below under 'NRMSE histograms' section\n",
    "    \n",
    "_____________\n",
    "    \n",
    "We should be able to use these methods to get most or all of our comparable results between modern ESN types and param settings. If you could use these to run your experiments too that'd be great (although they need to be modified before other types of models can be tried).\n",
    "\n",
    "I'll generalize the methods within a few days so you can run your experiments on them too (although if you want to do some tests before then you can do it if you wabt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from ESN.ESN import ESN, LCESN, EESN, DHESN\n",
    "from MackeyGlass.MackeyGlassGenerator import run\n",
    "from Helper.utils import nrmse, _DEFAULT_SPECS_\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "data = np.array(run(21100)).reshape(-1, 1)\n",
    "split = 20000\n",
    "X_train = data[:split-1]\n",
    "y_train = data[1:split]\n",
    "valid_data = data[split:].squeeze()\n",
    "\n",
    "data_mean = np.mean(data.squeeze())\n",
    "\n",
    "# zero the data (for PCA)\n",
    "X_train -= data_mean\n",
    "y_train -= data_mean\n",
    "valid_data -= data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basic ESN experiments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# baseline ESN \n",
    "esn = ESN(1, 1, 1000, echo_param=0.85, regulariser=1e-6)\n",
    "esn.initialize_input_weights(scale=1.0)\n",
    "esn.initialize_reservoir_weights(spectral_scale=1.25)\n",
    "esn.train(X_train, y_train)\n",
    "\n",
    "# generative tests\n",
    "u_n = data[split-1]\n",
    "esn_outputs = []\n",
    "for _ in range(len(valid_data)):\n",
    "    u_n = esn.forward(u_n)\n",
    "    esn_outputs.append(u_n)\n",
    "    \n",
    "esn_outputs = np.array(esn_outputs).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "esn_nrmse = nrmse(valid_data, esn_outputs, data_mean)\n",
    "print('ESN got %.4f NRMSE' % esn_nrmse)\n",
    "xs = range(len(valid_data))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.plot(xs, valid_data, label='True data')\n",
    "ax.plot(xs, esn_outputs, label='ESN outputs')\n",
    "#ax.plot(xs, [valid_mean]*len(xs), label='True data mean', linestyle='--', color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(esn_class, all_results, specs, n_runs=50, show_plots=False, fname=None):\n",
    "    \"\"\"\n",
    "    Generic method running tests on ESN.\n",
    "    \n",
    "    (ESN.LayeredESN)    esn_class: choose from [ESN, LCESN, DHESN, EESN].\n",
    "              (dict)  all_results: dictionary to save results in.\n",
    "              (dict)        specs: network specifications dictionary.\n",
    "               (str)        fname: filename to save results under.\n",
    "    \"\"\"\n",
    "    assert esn_class in [ESN, LCESN, EESN, DHESN]\n",
    "    \n",
    "    echo_params = specs['echo_params']\n",
    "    regulariser = specs['regulariser']\n",
    "    num_reservoirs = specs['num_reservoirs']\n",
    "    reservoir_sizes = specs['reservoir_sizes']\n",
    "    in_weights = specs['in_weights']\n",
    "    res_weights = specs['res_weights']\n",
    "    \n",
    "    in_notebook = os.environ['_'][-7:] == 'jupyter'\n",
    "    \n",
    "    if in_notebook:\n",
    "        progress_bar = IntProgress(value=0, min=0, max=n_runs)\n",
    "        display(progress_bar)\n",
    "        \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    for run_num in range(n_runs):\n",
    "        if not in_notebook:\n",
    "            print('Run %d' % (run_num+1))\n",
    "        # create and train model\n",
    "        lcesn = esn_class(1, 1, num_reservoirs, reservoir_sizes, echo_params, \n",
    "                      regulariser=regulariser)\n",
    "        lcesn.initialize_input_weights(\n",
    "            strategies=in_weights['strategies'], scales=in_weights['scales'],\n",
    "            offsets=in_weights['offsets']\n",
    "        )\n",
    "        lcesn.initialize_reservoir_weights(\n",
    "            strategies=res_weights['strategies'], spectral_scales=res_weights['spectral_scales'],\n",
    "            offsets=res_weights['offsets']\n",
    "        )\n",
    "        lcesn.train(X_train, y_train, debug_info=True)\n",
    "        lcesn_outputs = []\n",
    "\n",
    "        # generative tests\n",
    "        u_n = data[split-1]\n",
    "        for _ in range(len(valid_data)):\n",
    "            u_n = lcesn.forward(u_n)\n",
    "            lcesn_outputs.append(u_n)\n",
    "\n",
    "        lcesn_outputs = np.array(lcesn_outputs).squeeze()\n",
    "\n",
    "        error = nrmse(valid_data, lcesn_outputs, data_mean)\n",
    "        print('NRMSE: %f\\n' % error)\n",
    "        results.append(error)\n",
    "        \n",
    "        if show_plots:\n",
    "            f, ax = plt.subplots(figsize=(12, 10))\n",
    "            xs = range(len(valid_data))\n",
    "            ax.plot(xs, lcesn_outputs, label='Generated')\n",
    "            ax.plot(xs, valid_data, label='True')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            raw_input()\n",
    "        \n",
    "        if in_notebook:\n",
    "            if run_num == n_runs - 1:\n",
    "                progress_bar.close()\n",
    "            else:\n",
    "                progress_bar.value += 1\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print('Took %.3f seconds' % total_time)\n",
    "    n_runs = len(results)\n",
    "    key = [\n",
    "        'echo_params: %f' % echo_params, 'regulariser: %f' % regulariser,\n",
    "        'num_reservoirs: %d' % num_reservoirs, 'reservoir_sizes: %s' % reservoir_sizes,\n",
    "        'in_weights: %s' % in_weights.items(), 'res_weights: %s' % res_weights.items()\n",
    "    ]\n",
    "    for i in range(len(key)-1):\n",
    "        key[i] += '\\n'\n",
    "    key = ''.join(key)\n",
    "\n",
    "    if key not in all_results.keys():\n",
    "        all_results[key] = []\n",
    "\n",
    "    all_results[key].extend(results)\n",
    "    \n",
    "    while 1:\n",
    "        ch = raw_input('make sure you\\'re not overriding old results. (y/n)')\n",
    "        if ch == 'y':\n",
    "            if fname is None:\n",
    "                print('must provide a filename to save results')\n",
    "                break\n",
    "            elif fname[-2:] != '.p': \n",
    "                fname += '.p'\n",
    "            \n",
    "            class_str = str(esn_class)[16:-2]\n",
    "            assert class_str in ['ESN', 'DHESN', 'LCESN', 'EESN']\n",
    "            \n",
    "            pkl.dump(all_results, open('Results/%s/%s.p' % (class_str, fname), 'wb'))\n",
    "            break\n",
    "        elif ch == 'n':\n",
    "            print('okay, returning updated results dictionary instead')\n",
    "            break\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def show_nrmse_histograms(all_results, n_bins=30):\n",
    "    for k, res in all_results.items():\n",
    "        specs = k.split('\\n')\n",
    "        specs_dict = dict()\n",
    "        for s in specs:\n",
    "            #print(s)\n",
    "            if 'reservoir_sizes' in s:\n",
    "                sizes = s[s.index(':')+2:][1:-1]\n",
    "                sizes = map(int, sizes.split(','))\n",
    "            elif 'in_weights' in s or 'res_weights' in s:\n",
    "                info = s[s.index(':')+2:]\n",
    "                exec('info = dict(%s)' % info)\n",
    "                k_ = 'in_weights' if 'in_weights' in s else 'res_weights'\n",
    "                specs_dict[k_] = info\n",
    "            else:\n",
    "                k1 = \"'%s'\" % s[:s.index(':')]\n",
    "                k2 = s[s.index(':') + 2:]\n",
    "                exec('specs_dict[%s] = %s' % (k1, k2))\n",
    "\n",
    "        # Check for infs, nans\n",
    "        num_failed = 0\n",
    "        res_clean = []\n",
    "        for err in res:\n",
    "            if np.isnan(err) or np.isinf(err) or err >= 1.:\n",
    "                num_failed += 1\n",
    "            else:\n",
    "                res_clean.append(err)\n",
    "        \n",
    "        title = 'reg:%s. offset:%.1f. n_runs=%d. num_failures=%d' \\\n",
    "                    % (str(specs_dict['regulariser']), specs_dict['res_weights']['offsets'],\n",
    "                       len(res), num_failed)\n",
    "        if len(res_clean) > 0:\n",
    "            hist, bins = np.histogram(res_clean, bins=min(len(res_clean), n_bins))\n",
    "            bin_width = bins[1] - bins[0]\n",
    "\n",
    "            f, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.set_title(title)\n",
    "            ax.bar(bins[:-1], hist, width=bin_width)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('\"%s\" only yielded failures. oops' % title)\n",
    "        raw_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCESN experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = _DEFAULT_SPECS_\n",
    "specs['reservoir_sizes'] = [300, 230, 170, 100, 50]\n",
    "specs['spectral_scales'] = np.linspace(0.8, 0.9, 5)\n",
    "specs['in_weights']['scales'] = 0.1\n",
    "\n",
    "for k, v in specs.items():\n",
    "    print(k, v)\n",
    "\n",
    "all_results = run_test(DHESN, all_results, specs, n_runs=5, show_plots=True, \n",
    "                       fname='11_March.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NRMSE histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#show_nrmse_histograms(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Histograms (ignore)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_bins = 100\n",
    "state_hist, state_bins = np.histogram(esn_state.squeeze(), bins=n_bins)\n",
    "data_hist, data_bins = np.histogram(data[:1000].squeeze(), bins=n_bins)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16, 8))\n",
    "ax1.set_title('Reservoir states')\n",
    "ax2.set_title('First 1000 data points')\n",
    "\n",
    "ax1.bar(state_bins[:-1], state_hist)\n",
    "ax2.bar(data_bins[:-1], data_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f, axarr = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(16, 16))\n",
    "\n",
    "for reservoir in lcesn.reservoirs:\n",
    "    state = reservoir.state.squeeze()\n",
    "    st_hist, st_bins = np.histogram(state, bins=n_bins)\n",
    "    i = reservoir.idx\n",
    "    \n",
    "    \n",
    "    r, c = i / 2, i % 2\n",
    "    axarr[r][c].bar(st_bins[:-1], st_hist)\n",
    "    axarr[r][c].set_title('Reservoir %d states' % i)\n",
    "    \n",
    "axarr[-1][-1].bar(data_bins[:-1], data_hist)\n",
    "axarr[-1][-1].set_title('First 1000 data points')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 365,
   "position": {
    "height": "387px",
    "left": "514px",
    "right": "20px",
    "top": "149px",
    "width": "479px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
