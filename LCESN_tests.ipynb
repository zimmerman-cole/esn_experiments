{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Note to Levi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* I decided that any NRMSE above 1 should probably be considered a 'failure', since its worse than just predicting the mean anyways.\n",
    "______________\n",
    "* I made a method run_test() (under LCESN experiments) which takes a dictionary and filename (to save results) as input and runs tests using the parameters specified in the beginning of the function.\n",
    "    * right now it's written for LCESN, but can be easily changed so that the specific ESN class is passed as a parameter (although we'll have to change the \n",
    "    * For now you have to hard code the params you want in the beginning of the function, but I'll change it soon so you can pass params for grid searching etc.\n",
    "    * The results dictionary keys should contain all the necessary param information. The keys are created in a special way to make show_nrmse_histograms() work correctly.   \n",
    "______________\n",
    "* I also created a function show_nrmse_histograms() which takes one of the results dicts from run_test() and shows some cool histograms of generative NRMSEs yielded using the param settings in the dict. \n",
    "    * There's an example down below under 'NRMSE histograms' section\n",
    "    \n",
    "_____________\n",
    "    \n",
    "We should be able to use these methods to get most or all of our comparable results between modern ESN types and param settings. If you could use these to run your experiments too that'd be great (although they need to be modified before other types of models can be tried).\n",
    "\n",
    "I'll generalize the methods within a few days so you can run your experiments on them too (although if you want to do some tests before then you can do it if you wabt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from ESN.ESN import ESN, LCESN, EESN, DHESN\n",
    "from MackeyGlass.MackeyGlassGenerator import run\n",
    "from Helper.utils import nrmse\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "data = np.array(run(21100)).reshape(-1, 1)\n",
    "split = 20000\n",
    "X_train = data[:split-1]\n",
    "y_train = data[1:split]\n",
    "valid_data = data[split:].squeeze()\n",
    "\n",
    "data_mean = np.mean(data.squeeze())\n",
    "\n",
    "# zero the data (for PCA)\n",
    "X_train -= data_mean\n",
    "y_train -= data_mean\n",
    "valid_data -= data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basic ESN experiments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# baseline ESN \n",
    "esn = ESN(1, 1, 1000, echo_param=0.85, regulariser=1e-6)\n",
    "esn.initialize_input_weights(scale=1.0)\n",
    "esn.initialize_reservoir_weights(spectral_scale=1.25)\n",
    "esn.train(X_train, y_train)\n",
    "\n",
    "# generative tests\n",
    "u_n = data[split-1]\n",
    "esn_outputs = []\n",
    "for _ in range(len(valid_data)):\n",
    "    u_n = esn.forward(u_n)\n",
    "    esn_outputs.append(u_n)\n",
    "    \n",
    "esn_outputs = np.array(esn_outputs).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "esn_nrmse = nrmse(valid_data, esn_outputs, data_mean)\n",
    "print('ESN got %.4f NRMSE' % esn_nrmse)\n",
    "xs = range(len(valid_data))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.plot(xs, valid_data, label='True data')\n",
    "ax.plot(xs, esn_outputs, label='ESN outputs')\n",
    "#ax.plot(xs, [valid_mean]*len(xs), label='True data mean', linestyle='--', color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCESN experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5e73ee43e34a9ba94411f2680f3c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE: 461.799833\n",
      "\n",
      "NRMSE: 1.144619\n",
      "\n",
      "NRMSE: 1830.350125\n",
      "\n",
      "NRMSE: 665117.382804\n",
      "\n",
      "NRMSE: 245.667261\n",
      "\n",
      "NRMSE: 2565.522192\n",
      "\n",
      "NRMSE: 508.859625\n",
      "\n",
      "NRMSE: 67.558291\n",
      "\n",
      "NRMSE: 221.805672\n",
      "\n",
      "NRMSE: 659.088762\n",
      "\n",
      "NRMSE: 2.136218\n",
      "\n",
      "NRMSE: 563.091449\n",
      "\n",
      "NRMSE: 196.549513\n",
      "\n",
      "NRMSE: 144.840508\n",
      "\n",
      "NRMSE: 484.343840\n",
      "\n",
      "NRMSE: 642886.829195\n",
      "\n",
      "NRMSE: 666.374365\n",
      "\n",
      "NRMSE: 227.898461\n",
      "\n",
      "NRMSE: 1.783166\n",
      "\n",
      "NRMSE: 167.264539\n",
      "\n",
      "NRMSE: 170.450804\n",
      "\n",
      "NRMSE: 5035.619183\n",
      "\n",
      "NRMSE: 499.300633\n",
      "\n",
      "NRMSE: 191.719742\n",
      "\n",
      "NRMSE: 303.128191\n",
      "\n",
      "NRMSE: 10571.073281\n",
      "\n",
      "NRMSE: 668.961871\n",
      "\n",
      "NRMSE: 177813.423972\n",
      "\n",
      "NRMSE: 1.495895\n",
      "\n",
      "NRMSE: 9463790.641718\n",
      "\n",
      "NRMSE: 6983.519661\n",
      "\n",
      "NRMSE: 2.131873\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bd74b0f99d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDHESN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'9_March.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-bd74b0f99d0f>\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(esn_class, all_results, fname)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moffsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offsets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         )\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlcesn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mlcesn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cole/Desktop/esn_experiments/ESN/ESN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# burn-in period (init echo timesteps) ===============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mu_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreservoir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;31m# ==================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cole/Desktop/esn_experiments/ESN/ESN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, u_n)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0min_to_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mres_to_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Equation (1) in \"Formalism and Theory\" of Scholarpedia page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_test(esn_class, all_results, fname=None):\n",
    "    assert esn_class in [ESN, LCESN, EESN, DHESN]\n",
    "    \n",
    "    echo_params = 0.85\n",
    "    regulariser = 1e-3\n",
    "    num_reservoirs = 5\n",
    "    reservoir_sizes = [int(np.ceil(1000. / num_reservoirs))]*num_reservoirs\n",
    "    in_weights = {'strategies': 'binary', 'scales': 0.2, 'offsets': 0.5}\n",
    "    res_weights = {'strategies': 'uniform', 'spectral_scales': 1., 'offsets': 0.5}\n",
    "    n_runs = 50\n",
    "\n",
    "    assert sum(reservoir_sizes) == 1000\n",
    "    \n",
    "    in_notebook = os.environ['_'][-7:] == 'jupyter'\n",
    "    \n",
    "    if in_notebook:\n",
    "        progress_bar = IntProgress(value=0, min=0, max=n_runs)\n",
    "        display(progress_bar)\n",
    "        \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    for run_num in range(n_runs):\n",
    "        if not in_notebook:\n",
    "            print('Run %d' % (run_num+1))\n",
    "        # create and train model\n",
    "        lcesn = esn_class(1, 1, num_reservoirs, reservoir_sizes, echo_params, \n",
    "                      regulariser=regulariser)\n",
    "        lcesn.initialize_input_weights(\n",
    "            strategies=in_weights['strategies'], scales=in_weights['scales'],\n",
    "            offsets=in_weights['offsets']\n",
    "        )\n",
    "        lcesn.initialize_reservoir_weights(\n",
    "            strategies=res_weights['strategies'], spectral_scales=res_weights['spectral_scales'],\n",
    "            offsets=res_weights['offsets']\n",
    "        )\n",
    "        lcesn.train(X_train, y_train)\n",
    "        lcesn_outputs = []\n",
    "\n",
    "        # generative tests\n",
    "        u_n = data[split-1]\n",
    "        for _ in range(len(valid_data)):\n",
    "            u_n = lcesn.forward(u_n)\n",
    "            lcesn_outputs.append(u_n)\n",
    "\n",
    "        lcesn_outputs = np.array(lcesn_outputs).squeeze()\n",
    "\n",
    "        error = nrmse(valid_data, lcesn_outputs, data_mean)\n",
    "        print('NRMSE: %f\\n' % error)\n",
    "        results.append(error)\n",
    "        \n",
    "        if in_notebook:\n",
    "            if run_num == n_runs - 1:\n",
    "                progress_bar.close()\n",
    "            else:\n",
    "                progress_bar.value += 1\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print('Took %.3f seconds' % total_time)\n",
    "    n_runs = len(results)\n",
    "    key = [\n",
    "        'echo_params: %f' % echo_params, 'regulariser: %f' % regulariser,\n",
    "        'num_reservoirs: %d' % num_reservoirs, 'reservoir_sizes: %s' % reservoir_sizes,\n",
    "        'in_weights: %s' % in_weights.items(), 'res_weights: %s' % res_weights.items()\n",
    "    ]\n",
    "    for i in range(len(key)-1):\n",
    "        key[i] += '\\n'\n",
    "    key = ''.join(key)\n",
    "\n",
    "    if key not in all_results.keys():\n",
    "        all_results[key] = []\n",
    "\n",
    "    all_results[key].extend(results)\n",
    "    \n",
    "    while 1:\n",
    "        ch = raw_input('make sure you\\'re not overriding old results. (y/n)')\n",
    "        if ch == 'y':\n",
    "            if fname is None:\n",
    "                print('must provide a filename to save results')\n",
    "                break\n",
    "            elif fname[-2:] != '.p': \n",
    "                fname += '.p'\n",
    "            \n",
    "            class_str = str(esn_class)[16:-2]\n",
    "            assert class_str in ['ESN', 'DHESN', 'LCESN', 'EESN']\n",
    "            \n",
    "            pkl.dump(all_results, open('Results/%s/%s.p' % (class_str, fname), 'wb'))\n",
    "            break\n",
    "        elif ch == 'n':\n",
    "            print('okay, returning updated results dictionary instead')\n",
    "            break\n",
    "    \n",
    "    return all_results\n",
    "    \n",
    "all_results = run_test(DHESN, all_results, fname='9_March.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NRMSE histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_nrmse_histograms(all_results, n_bins=30):\n",
    "    for k, res in all_results.items():\n",
    "        specs = k.split('\\n')\n",
    "        specs_dict = dict()\n",
    "        for s in specs:\n",
    "            #print(s)\n",
    "            if 'reservoir_sizes' in s:\n",
    "                sizes = s[s.index(':')+2:][1:-1]\n",
    "                sizes = map(int, sizes.split(','))\n",
    "            elif 'in_weights' in s or 'res_weights' in s:\n",
    "                info = s[s.index(':')+2:]\n",
    "                exec('info = dict(%s)' % info)\n",
    "                k_ = 'in_weights' if 'in_weights' in s else 'res_weights'\n",
    "                specs_dict[k_] = info\n",
    "            else:\n",
    "                k1 = \"'%s'\" % s[:s.index(':')]\n",
    "                k2 = s[s.index(':') + 2:]\n",
    "                exec('specs_dict[%s] = %s' % (k1, k2))\n",
    "\n",
    "        # Check for infs, nans\n",
    "        num_failed = 0\n",
    "        res_clean = []\n",
    "        for err in res:\n",
    "            if np.isnan(err) or np.isinf(err) or err >= 1.:\n",
    "                num_failed += 1\n",
    "            else:\n",
    "                res_clean.append(err)\n",
    "        \n",
    "        title = 'reg:%s. offset:%.1f. n_runs=%d. num_failures=%d' \\\n",
    "                    % (str(specs_dict['regulariser']), specs_dict['res_weights']['offsets'],\n",
    "                       len(res), num_failed)\n",
    "        if len(res_clean) > 0:\n",
    "            hist, bins = np.histogram(res_clean, bins=min(len(res_clean), n_bins))\n",
    "            bin_width = bins[1] - bins[0]\n",
    "\n",
    "            f, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.set_title(title)\n",
    "            ax.bar(bins[:-1], hist, width=bin_width)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('\"%s\" only yielded failures. oops' % title)\n",
    "        raw_input()\n",
    "        \n",
    "#show_nrmse_histograms(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Histograms (ignore)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_bins = 100\n",
    "state_hist, state_bins = np.histogram(esn_state.squeeze(), bins=n_bins)\n",
    "data_hist, data_bins = np.histogram(data[:1000].squeeze(), bins=n_bins)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16, 8))\n",
    "ax1.set_title('Reservoir states')\n",
    "ax2.set_title('First 1000 data points')\n",
    "\n",
    "ax1.bar(state_bins[:-1], state_hist)\n",
    "ax2.bar(data_bins[:-1], data_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f, axarr = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(16, 16))\n",
    "\n",
    "for reservoir in lcesn.reservoirs:\n",
    "    state = reservoir.state.squeeze()\n",
    "    st_hist, st_bins = np.histogram(state, bins=n_bins)\n",
    "    i = reservoir.idx\n",
    "    \n",
    "    \n",
    "    r, c = i / 2, i % 2\n",
    "    axarr[r][c].bar(st_bins[:-1], st_hist)\n",
    "    axarr[r][c].set_title('Reservoir %d states' % i)\n",
    "    \n",
    "axarr[-1][-1].bar(data_bins[:-1], data_hist)\n",
    "axarr[-1][-1].set_title('First 1000 data points')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 365,
   "position": {
    "height": "387px",
    "left": "514px",
    "right": "20px",
    "top": "149px",
    "width": "479px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
